# Pooling layers

The pooling layers from these papers are available in Spektral:

- [Hierarchical Graph Representation Learning with Differentiable Pooling](https://arxiv.org/abs/1806.08804)
- [Mincut pooling in Graph Neural Networks](https://arxiv.org/abs/1907.00481)
- [Graph U-Nets](http://proceedings.mlr.press/v97/gao19a/gao19a.pdf)
- [Self-Attention Graph Pooling](https://arxiv.org/abs/1904.08082)
- [Gated Graph Sequence Neural Networks](https://arxiv.org/abs/1511.05493)

Additionally, sum, average, and max global pooling are implemented, as well as 
a simple global weighted sum pooling where weights are calculated with an 
attention mechanism. 

See [the convolutional layers page](/layers/convolution) for the notation. 

---

{{autogenerated}}
