<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Daniele Grattarola">
  <link rel="canonical" href="https://graphneural.network/layers/pooling/">
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Pooling layers - Spektral</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../../css/theme.css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  <link href="../../stylesheets/extra.css" rel="stylesheet" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Pooling layers";
    var mkdocs_page_input_path = "layers/pooling.md";
    var mkdocs_page_url = "/layers/pooling/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js" defer></script>
  <script src="../../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-125823175-1', 'auto');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Spektral</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../..">Home</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Tutorials</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../getting-started/">Getting started</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../data-modes/">Data modes</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../creating-dataset/">Creating a dataset</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../creating-layer/">Creating a layer</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../examples/">Examples</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Layers</span></p>
                <ul class="current">
                    <li class="toctree-l1"><a class="reference internal" href="../convolution/">Convolutional layers</a>
                    </li>
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Pooling layers</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#diffpool">DiffPool</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#mincutpool">MinCutPool</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#sagpool">SAGPool</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#topkpool">TopKPool</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#global-pooling-layers">Global pooling layers</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#globalavgpool">GlobalAvgPool</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#globalmaxpool">GlobalMaxPool</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#globalsumpool">GlobalSumPool</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#globalattentionpool">GlobalAttentionPool</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#globalattnsumpool">GlobalAttnSumPool</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#sortpool">SortPool</a>
    </li>
        </ul>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../base/">Base layers</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../models/">Models</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Data</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../data/">Containers</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../datasets/">Datasets</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../loaders/">Loaders</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../transforms/">Transforms</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Utils</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../utils/convolution/">Convolution</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../utils/sparse/">Sparse</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../utils/misc/">Miscellaneous</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Other</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../../external/">External resources</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../../about/">About</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Spektral</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Layers &raquo;</li>
        
      
    
    <li>Pooling layers</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <h2 id="pooling-layers">Pooling layers</h2>
<p>The following pooling layers are available in Spektral.</p>
<p>See <a href="/layers/convolution">the convolutional layers page</a> for the notation. </p>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/diff_pool.py#L10">[source]</a></span></p>
<h4 id="diffpool">DiffPool</h4>
<pre><code class="language-python">spektral.layers.DiffPool(k, channels=None, return_mask=False, activation=None, kernel_initializer='glorot_uniform', kernel_regularizer=None, kernel_constraint=None)
</code></pre>
<p>A DiffPool layer from the paper</p>
<blockquote>
<p><a href="https://arxiv.org/abs/1806.08804">Hierarchical Graph Representation Learning with Differentiable Pooling</a><br>
Rex Ying et al.</p>
</blockquote>
<p><strong>Mode</strong>: batch.</p>
<p>This layer computes a soft clustering <script type="math/tex">\S</script> of the input graphs using a GNN,
and reduces graphs as follows:
<script type="math/tex; mode=display">
\begin{align}
\S &= \textrm{GNN}_{embed}(\A, \X); \\
\Z &= \textrm{GNN}_{pool}(\A, \X); \\
\A' &= \S^\top \A \S; \\
\X' &= \S^\top \Z
\end{align}
</script>
where:
<script type="math/tex; mode=display">
\textrm{GNN}_{\square}(\A, \X) = \D^{-1/2} \A \D^{-1/2} \X \W_{\square}.
</script>
The number of output channels of <script type="math/tex">\textrm{GNN}_{embed}</script> is controlled by 
the <code>channels</code> parameter.</p>
<p>Two auxiliary loss terms are also added to the model: the <em>link prediction
loss</em>
<script type="math/tex; mode=display">
L_{LP} = \big\| \A - \S\S^\top \big\|_F
</script>
and the <em>entropy loss</em>
<script type="math/tex; mode=display">
L_{E} - \frac{1}{N} \sum\limits_{i = 1}^{N} \S \log (\S).
</script>
</p>
<p>The layer can be used without a supervised loss, to compute node clustering
simply by minimizing the two auxiliary losses.</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>([batch], n_nodes, n_node_features)</code>;</li>
<li>Adjacency matrix of shape <code>([batch], n_nodes, n_nodes)</code>;</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Reduced node features of shape <code>([batch], K, channels)</code>;</li>
<li>Reduced adjacency matrix of shape <code>([batch], K, K)</code>;</li>
<li>If <code>return_mask=True</code>, the soft clustering matrix of shape <code>([batch], n_nodes, K)</code>.</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>k</code>: number of output nodes;</li>
<li><code>channels</code>: number of output channels (if None, the number of output
channels is assumed to be the same as the input);</li>
<li><code>return_mask</code>: boolean, whether to return the cluster assignment matrix;</li>
<li><code>kernel_initializer</code>: initializer for the weights;</li>
<li><code>kernel_regularizer</code>: regularization applied to the weights;</li>
<li><code>kernel_constraint</code>: constraint applied to the weights;</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/mincut_pool.py#L10">[source]</a></span></p>
<h4 id="mincutpool">MinCutPool</h4>
<pre><code class="language-python">spektral.layers.MinCutPool(k, mlp_hidden=None, mlp_activation='relu', return_mask=False, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None)
</code></pre>
<p>A MinCut pooling layer from the paper</p>
<blockquote>
<p><a href="https://arxiv.org/abs/1907.00481">Spectral Clustering with Graph Neural Networks for Graph Pooling</a><br>
Filippo Maria Bianchi et al.</p>
</blockquote>
<p><strong>Mode</strong>: batch.</p>
<p>This layer computes a soft clustering <script type="math/tex">\S</script> of the input graphs using a MLP,
and reduces graphs as follows:
<script type="math/tex; mode=display">
\begin{align}
\S &= \textrm{MLP}(\X); \\
\A' &= \S^\top \A \S; \\ 
\X' &= \S^\top \X
\end{align}
</script>
where MLP is a multi-layer perceptron with softmax output.</p>
<p>Two auxiliary loss terms are also added to the model: the <em>minCUT loss</em>
<script type="math/tex; mode=display">
L_c = - \frac{ \mathrm{Tr}(\S^\top \A \S) }{ \mathrm{Tr}(\S^\top \D \S) }
</script>
and the <em>orthogonality loss</em>
<script type="math/tex; mode=display">
L_o = \left\|
\frac{\S^\top \S}{\| \S^\top \S \|_F}
- \frac{\I_K}{\sqrt{K}}
\right\|_F.
</script>
</p>
<p>The layer can be used without a supervised loss, to compute node clustering
simply by minimizing the two auxiliary losses.</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>([batch], n_nodes, n_node_features)</code>;</li>
<li>Symmetrically normalized adjacency matrix of shape <code>([batch], n_nodes, n_nodes)</code>;</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Reduced node features of shape <code>([batch], K, n_node_features)</code>;</li>
<li>Reduced adjacency matrix of shape <code>([batch], K, K)</code>;</li>
<li>If <code>return_mask=True</code>, the soft clustering matrix of shape <code>([batch], n_nodes, K)</code>.</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>k</code>: number of output nodes;</li>
<li><code>mlp_hidden</code>: list of integers, number of hidden units for each hidden
layer in the MLP used to compute cluster assignments (if None, the MLP has
only the output layer);</li>
<li><code>mlp_activation</code>: activation for the MLP layers;</li>
<li><code>return_mask</code>: boolean, whether to return the cluster assignment matrix;</li>
<li><code>use_bias</code>: use bias in the MLP;</li>
<li><code>kernel_initializer</code>: initializer for the weights of the MLP;</li>
<li><code>bias_initializer</code>: initializer for the bias of the MLP;</li>
<li><code>kernel_regularizer</code>: regularization applied to the weights of the MLP;</li>
<li><code>bias_regularizer</code>: regularization applied to the bias of the MLP;</li>
<li><code>kernel_constraint</code>: constraint applied to the weights of the MLP;</li>
<li><code>bias_constraint</code>: constraint applied to the bias of the MLP;</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/sag_pool.py#L6">[source]</a></span></p>
<h4 id="sagpool">SAGPool</h4>
<pre><code class="language-python">spektral.layers.SAGPool(ratio, return_mask=False, sigmoid_gating=False, kernel_initializer='glorot_uniform', kernel_regularizer=None, kernel_constraint=None)
</code></pre>
<p>A self-attention graph pooling layer from the paper</p>
<blockquote>
<p><a href="https://arxiv.org/abs/1904.08082">Self-Attention Graph Pooling</a><br>
Junhyun Lee et al.</p>
</blockquote>
<p><strong>Mode</strong>: single, disjoint.</p>
<p>This layer computes the following operations:
<script type="math/tex; mode=display">
\y = \textrm{GNN}(\A, \X); \;\;\;\;
\i = \textrm{rank}(\y, K); \;\;\;\;
\X' = (\X \odot \textrm{tanh}(\y))_\i; \;\;\;\;
\A' = \A_{\i, \i}
</script>
where <script type="math/tex">\textrm{rank}(\y, K)</script> returns the indices of the top K values of
<script type="math/tex">\y</script> and
<script type="math/tex; mode=display">
\textrm{GNN}(\A, \X) = \A \X \W.
</script>
</p>
<p>
<script type="math/tex">K</script> is defined for each graph as a fraction of the number of nodes,
controlled by the <code>ratio</code> argument.</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>(n_nodes, n_node_features)</code>;</li>
<li>Binary adjacency matrix of shape <code>(n_nodes, n_nodes)</code>;</li>
<li>Graph IDs of shape <code>(n_nodes, )</code> (only in disjoint mode);</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Reduced node features of shape <code>(ratio * n_nodes, n_node_features)</code>;</li>
<li>Reduced adjacency matrix of shape <code>(ratio * n_nodes, ratio * n_nodes)</code>;</li>
<li>Reduced graph IDs of shape <code>(ratio * n_nodes, )</code> (only in disjoint mode);</li>
<li>If <code>return_mask=True</code>, the binary pooling mask of shape <code>(ratio * n_nodes, )</code>.</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>ratio</code>: float between 0 and 1, ratio of nodes to keep in each graph;</li>
<li><code>return_mask</code>: boolean, whether to return the binary mask used for pooling;</li>
<li><code>sigmoid_gating</code>: boolean, use a sigmoid gating activation instead of a
tanh;</li>
<li><code>kernel_initializer</code>: initializer for the weights;</li>
<li><code>kernel_regularizer</code>: regularization applied to the weights;</li>
<li><code>kernel_constraint</code>: constraint applied to the weights;</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/topk_pool.py#L8">[source]</a></span></p>
<h4 id="topkpool">TopKPool</h4>
<pre><code class="language-python">spektral.layers.TopKPool(ratio, return_mask=False, sigmoid_gating=False, kernel_initializer='glorot_uniform', kernel_regularizer=None, kernel_constraint=None)
</code></pre>
<p>A gPool/Top-K layer from the papers</p>
<blockquote>
<p><a href="https://arxiv.org/abs/1905.05178">Graph U-Nets</a><br>
Hongyang Gao and Shuiwang Ji</p>
</blockquote>
<p>and</p>
<blockquote>
<p><a href="https://arxiv.org/abs/1811.01287">Towards Sparse Hierarchical Graph Classifiers</a><br>
Cătălina Cangea et al.</p>
</blockquote>
<p><strong>Mode</strong>: single, disjoint.</p>
<p>This layer computes the following operations:
<script type="math/tex; mode=display">
\y = \frac{\X\p}{\|\p\|}; \;\;\;\;
\i = \textrm{rank}(\y, K); \;\;\;\;
\X' = (\X \odot \textrm{tanh}(\y))_\i; \;\;\;\;
\A' = \A_{\i, \i}
</script>
where <script type="math/tex">\textrm{rank}(\y, K)</script> returns the indices of the top K values of
<script type="math/tex">\y</script>, and <script type="math/tex">\p</script> is a learnable parameter vector of size <script type="math/tex">F</script>.</p>
<p>
<script type="math/tex">K</script> is defined for each graph as a fraction of the number of nodes,
controlled by the <code>ratio</code> argument.</p>
<p>Note that the the gating operation <script type="math/tex">\textrm{tanh}(\y)</script> (Cangea et al.)
can be replaced with a sigmoid (Gao &amp; Ji).</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>(n_nodes, n_node_features)</code>;</li>
<li>Binary adjacency matrix of shape <code>(n_nodes, n_nodes)</code>;</li>
<li>Graph IDs of shape <code>(n_nodes, )</code> (only in disjoint mode);</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Reduced node features of shape <code>(ratio * n_nodes, n_node_features)</code>;</li>
<li>Reduced adjacency matrix of shape <code>(ratio * n_nodes, ratio * n_nodes)</code>;</li>
<li>Reduced graph IDs of shape <code>(ratio * n_nodes, )</code> (only in disjoint mode);</li>
<li>If <code>return_mask=True</code>, the binary pooling mask of shape <code>(ratio * n_nodes, )</code>.</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>ratio</code>: float between 0 and 1, ratio of nodes to keep in each graph;</li>
<li><code>return_mask</code>: boolean, whether to return the binary mask used for pooling;</li>
<li><code>sigmoid_gating</code>: boolean, use a sigmoid gating activation instead of a
tanh;</li>
<li><code>kernel_initializer</code>: initializer for the weights;</li>
<li><code>kernel_regularizer</code>: regularization applied to the weights;</li>
<li><code>kernel_constraint</code>: constraint applied to the weights;</li>
</ul>
<hr />
<h3 id="global-pooling-layers">Global pooling layers</h3>
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/global_pool.py#L82">[source]</a></span></p>
<h4 id="globalavgpool">GlobalAvgPool</h4>
<pre><code class="language-python">spektral.layers.GlobalAvgPool()
</code></pre>
<p>An average pooling layer. Pools a graph by computing the average of its node
features.</p>
<p><strong>Mode</strong>: single, disjoint, mixed, batch.</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>([batch], n_nodes, n_node_features)</code>;</li>
<li>Graph IDs of shape <code>(n_nodes, )</code> (only in disjoint mode);</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Pooled node features of shape <code>(batch, n_node_features)</code> (if single mode, shape will
be <code>(1, n_node_features)</code>).</li>
</ul>
<p><strong>Arguments</strong></p>
<p>None.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/global_pool.py#L111">[source]</a></span></p>
<h4 id="globalmaxpool">GlobalMaxPool</h4>
<pre><code class="language-python">spektral.layers.GlobalMaxPool()
</code></pre>
<p>A max pooling layer. Pools a graph by computing the maximum of its node
features.</p>
<p><strong>Mode</strong>: single, disjoint, mixed, batch.</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>([batch], n_nodes, n_node_features)</code>;</li>
<li>Graph IDs of shape <code>(n_nodes, )</code> (only in disjoint mode);</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Pooled node features of shape <code>(batch, n_node_features)</code> (if single mode, shape will
be <code>(1, n_node_features)</code>).</li>
</ul>
<p><strong>Arguments</strong></p>
<p>None.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/global_pool.py#L53">[source]</a></span></p>
<h4 id="globalsumpool">GlobalSumPool</h4>
<pre><code class="language-python">spektral.layers.GlobalSumPool()
</code></pre>
<p>A global sum pooling layer. Pools a graph by computing the sum of its node
features.</p>
<p><strong>Mode</strong>: single, disjoint, mixed, batch.</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>([batch], n_nodes, n_node_features)</code>;</li>
<li>Graph IDs of shape <code>(n_nodes, )</code> (only in disjoint mode);</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Pooled node features of shape <code>(batch, n_node_features)</code> (if single mode, shape will
be <code>(1, n_node_features)</code>).</li>
</ul>
<p><strong>Arguments</strong></p>
<p>None.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/global_pool.py#L140">[source]</a></span></p>
<h4 id="globalattentionpool">GlobalAttentionPool</h4>
<pre><code class="language-python">spektral.layers.GlobalAttentionPool(channels, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, kernel_constraint=None, bias_constraint=None)
</code></pre>
<p>A gated attention global pooling layer from the paper</p>
<blockquote>
<p><a href="https://arxiv.org/abs/1511.05493">Gated Graph Sequence Neural Networks</a><br>
Yujia Li et al.</p>
</blockquote>
<p>This layer computes:
<script type="math/tex; mode=display">
\X' = \sum\limits_{i=1}^{N} (\sigma(\X \W_1 + \b_1) \odot (\X \W_2 + \b_2))_i
</script>
where <script type="math/tex">\sigma</script> is the sigmoid activation function.</p>
<p><strong>Mode</strong>: single, disjoint, mixed, batch.</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>([batch], n_nodes, n_node_features)</code>;</li>
<li>Graph IDs of shape <code>(n_nodes, )</code> (only in disjoint mode);</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Pooled node features of shape <code>(batch, channels)</code> (if single mode,
shape will be <code>(1, channels)</code>).</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>channels</code>: integer, number of output channels;</li>
<li><code>bias_initializer</code>: initializer for the bias vectors;</li>
<li><code>kernel_regularizer</code>: regularization applied to the kernel matrices;</li>
<li><code>bias_regularizer</code>: regularization applied to the bias vectors;</li>
<li><code>kernel_constraint</code>: constraint applied to the kernel matrices;</li>
<li><code>bias_constraint</code>: constraint applied to the bias vectors.</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/global_pool.py#L254">[source]</a></span></p>
<h4 id="globalattnsumpool">GlobalAttnSumPool</h4>
<pre><code class="language-python">spektral.layers.GlobalAttnSumPool(attn_kernel_initializer='glorot_uniform', attn_kernel_regularizer=None, attn_kernel_constraint=None)
</code></pre>
<p>A node-attention global pooling layer. Pools a graph by learning attention
coefficients to sum node features.</p>
<p>This layer computes:
<script type="math/tex; mode=display">
\alpha = \textrm{softmax}( \X \a); \\
\X' = \sum\limits_{i=1}^{N} \alpha_i \cdot \X_i
</script>
where <script type="math/tex">\a \in \mathbb{R}^F</script> is a trainable vector. Note that the softmax
is applied across nodes, and not across features.</p>
<p><strong>Mode</strong>: single, disjoint, mixed, batch.</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>([batch], n_nodes, n_node_features)</code>;</li>
<li>Graph IDs of shape <code>(n_nodes, )</code> (only in disjoint mode);</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Pooled node features of shape <code>(batch, n_node_features)</code> (if single mode, shape will
be <code>(1, n_node_features)</code>).</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>attn_kernel_initializer</code>: initializer for the attention weights;</li>
<li><code>attn_kernel_regularizer</code>: regularization applied to the attention kernel
matrix;</li>
<li><code>attn_kernel_constraint</code>: constraint applied to the attention kernel
matrix;</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/layers/pooling/global_pool.py#L351">[source]</a></span></p>
<h4 id="sortpool">SortPool</h4>
<pre><code class="language-python">spektral.layers.SortPool(k)
</code></pre>
<p>A SortPool layer as described by
<a href="https://www.cse.wustl.edu/~muhan/papers/AAAI_2018_DGCNN.pdf">Zhang et al</a>.
This layers takes a graph signal <script type="math/tex">\mathbf{X}</script> and returns the topmost k
rows according to the last column.
If <script type="math/tex">\mathbf{X}</script> has less than k rows, the result is zero-padded to k.</p>
<p><strong>Mode</strong>: single, disjoint, batch.</p>
<p><strong>Input</strong></p>
<ul>
<li>Node features of shape <code>([batch], n_nodes, n_node_features)</code>;</li>
<li>Graph IDs of shape <code>(n_nodes, )</code> (only in disjoint mode);</li>
</ul>
<p><strong>Output</strong></p>
<ul>
<li>Pooled node features of shape <code>(batch, k, n_node_features)</code> (if single mode, shape will
be <code>(1, k, n_node_features)</code>).</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>k</code>: integer, number of nodes to keep;</li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../base/" class="btn btn-neutral float-right" title="Base layers">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../convolution/" class="btn btn-neutral" title="Convolutional layers"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/danielegrattarola/spektral/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../convolution/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../base/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../../js/macros.js" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
