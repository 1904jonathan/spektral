<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Daniele Grattarola">
  <link rel="canonical" href="https://graphneural.network/loaders/">
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Loaders - Spektral</title>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700" />

  <link rel="stylesheet" href="../css/theme.css" />
  <link rel="stylesheet" href="../css/theme_extra.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
  <link href="../stylesheets/extra.css" rel="stylesheet" />
  
  <script>
    // Current page data
    var mkdocs_page_name = "Loaders";
    var mkdocs_page_input_path = "loaders.md";
    var mkdocs_page_url = "/loaders/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-125823175-1', 'auto');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Spektral</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="..">Home</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Tutorials</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../getting-started/">Getting started</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../data-modes/">Data modes</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../creating-dataset/">Creating a dataset</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../creating-layer/">Creating a layer</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../examples/">Examples</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Layers</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../layers/convolution/">Convolutional layers</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../layers/pooling/">Pooling layers</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../layers/base/">Base layers</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../models/">Models</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Data</span></p>
                <ul class="current">
                    <li class="toctree-l1"><a class="reference internal" href="../data/">Containers</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../datasets/">Datasets</a>
                    </li>
                    <li class="toctree-l1 current"><a class="reference internal current" href="./">Loaders</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#loader">Loader</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#singleloader">SingleLoader</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#disjointloader">DisjointLoader</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#batchloader">BatchLoader</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#packedbatchloader">PackedBatchLoader</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#mixedloader">MixedLoader</a>
    </li>
    </ul>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../transforms/">Transforms</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Utils</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../utils/convolution/">Convolution</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../utils/sparse/">Sparse</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../utils/misc/">Miscellaneous</a>
                    </li>
                </ul>
                <p class="caption"><span class="caption-text">Other</span></p>
                <ul>
                    <li class="toctree-l1"><a class="reference internal" href="../external/">External resources</a>
                    </li>
                    <li class="toctree-l1"><a class="reference internal" href="../about/">About</a>
                    </li>
                </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Spektral</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Data &raquo;</li>
        
      
    
    <li>Loaders</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  
  <hr/>
</div>

          <div role="main">
            <div class="section">
              
                <h2 id="loaders">Loaders</h2>
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/data/loaders.py#L21">[source]</a></span></p>
<h4 id="loader">Loader</h4>
<pre><code class="language-python">spektral.data.loaders.Loader(dataset, batch_size=1, epochs=None, shuffle=True)
</code></pre>
<p>Parent class for data loaders. The role of a Loader is to iterate over a
Dataset and yield batches of graphs to feed your Keras Models.</p>
<p>This is achieved by having a generator object that produces lists of Graphs,
which are then collated together and returned as Tensors.</p>
<p>The core of a Loader is the <code>collate(batch)</code> method.
This takes as input a list of <code>Graph</code> objects and returns a list of Tensors,
np.arrays, or SparseTensors.</p>
<p>For instance, if all graphs have the same number of nodes and size of the
attributes, a simple collation function can be:</p>
<pre><code class="language-python">def collate(self, batch):
    x = np.array([g.x for g in batch])
    a = np.array([g.a for g in batch)]
    return x, a
</code></pre>
<p>The <code>load()</code> method of a Loader returns an object that can be passed to a Keras
model when using the <code>fit</code>, <code>predict</code> and <code>evaluate</code> functions.
You can use it as follows:</p>
<pre><code class="language-python">model.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch)
</code></pre>
<p>The <code>steps_per_epoch</code> property represents the number of batches that are in
an epoch, and is a required keyword when calling <code>fit</code>, <code>predict</code> or <code>evaluate</code>
with a Loader.</p>
<p>If you are using a custom training function, you can specify the input signature
of your batches with the tf.TypeSpec system to avoid unnecessary re-tracings.
The signature is computed automatically by calling <code>loader.tf_signature()</code>.</p>
<p>For example, a simple training step can be written as:</p>
<pre><code class="language-python">@tf.function(input_signature=loader.tf_signature())  # Specify signature here
def train_step(inputs, target):
    with tf.GradientTape() as tape:
        predictions = model(inputs, training=True)
        loss = loss_fn(target, predictions)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
</code></pre>
<p>We can then train our model in a loop as follows:</p>
<pre><code class="language-python">for batch in loader:
    train_step(*batch)
</code></pre>
<p><strong>Arguments</strong></p>
<ul>
<li><code>dataset</code>: a <code>spektral.data.Dataset</code> object;</li>
<li><code>batch_size</code>: size of the mini-batches;</li>
<li><code>epochs</code>: number of epochs to iterate over the dataset. By default (<code>None</code>)
iterates indefinitely;</li>
<li><code>shuffle</code>: whether to shuffle the dataset at the start of each epoch.</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/data/loaders.py#L168">[source]</a></span></p>
<h4 id="singleloader">SingleLoader</h4>
<pre><code class="language-python">spektral.data.loaders.SingleLoader(dataset, epochs=None, sample_weights=None)
</code></pre>
<p>A Loader for <a href="https://graphneural.network/data-modes/#single-mode">single mode</a>.</p>
<p>This loader produces Tensors representing a single graph. As such, it can
only be used with Datasets of length 1 and the <code>batch_size</code> cannot be set.</p>
<p>The loader supports sample weights through the <code>sample_weights</code> argument.
If given, then each batch will be a tuple <code>(inputs, labels, sample_weights)</code>.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>dataset</code>: a <code>spektral.data.Dataset</code> object with only one graph;</li>
<li><code>epochs</code>: number of epochs to iterate over the dataset. By default (<code>None</code>)
iterates indefinitely;</li>
<li><code>shuffle</code>: whether to shuffle the data at the start of each epoch;</li>
<li><code>sample_weights</code>: if given, these will be appended to the output
automatically.</li>
</ul>
<p><strong>Output</strong></p>
<p>Returns a tuple <code>(inputs, labels)</code> or <code>(inputs, labels, sample_weights)</code>.</p>
<p><code>inputs</code> is a tuple containing the data matrices of the graph, only if they
are not <code>None</code>:</p>
<ul>
<li><code>x</code>: same as <code>dataset[0].x</code>;</li>
<li><code>a</code>: same as <code>dataset[0].a</code> (scipy sparse matrices are converted to
SparseTensors);</li>
<li><code>e</code>: same as <code>dataset[0].e</code>;</li>
</ul>
<p><code>labels</code> is the same as <code>dataset[0].y</code>.
<code>sample_weights</code> is the same object passed to the constructor.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/data/loaders.py#L244">[source]</a></span></p>
<h4 id="disjointloader">DisjointLoader</h4>
<pre><code class="language-python">spektral.data.loaders.DisjointLoader(dataset, node_level=False, batch_size=1, epochs=None, shuffle=True)
</code></pre>
<p>A Loader for <a href="https://graphneural.network/data-modes/#disjoint-mode">disjoint mode</a>.</p>
<p>This loader represents a batch of graphs via their disjoint union.</p>
<p>The loader automatically computes a batch index tensor, containing integer
indices that map each node to its corresponding graph in the batch.</p>
<p>The adjacency matrix os returned as a SparseTensor, regardless of the input.</p>
<p>If <code>node_level=False</code>, the labels are interpreted as graph-level labels and
are stacked along an additional dimension.
If <code>node_level=True</code>, then the labels are stacked vertically.</p>
<p><strong>Note:</strong> TensorFlow 2.4 or above is required to use this Loader's <code>load()</code>
method in a Keras training loop.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>dataset</code>: a graph Dataset;</li>
<li><code>batch_size</code>: size of the mini-batches;</li>
<li><code>epochs</code>: number of epochs to iterate over the dataset. By default (<code>None</code>)
iterates indefinitely;</li>
<li><code>shuffle</code>: whether to shuffle the data at the start of each epoch.</li>
</ul>
<p><strong>Output</strong></p>
<p>For each batch, returns a tuple <code>(inputs, labels)</code>.</p>
<p><code>inputs</code> is a tuple containing:</p>
<ul>
<li><code>x</code>: node attributes of shape <code>[n_nodes, n_node_features]</code>;</li>
<li><code>a</code>: adjacency matrices of shape <code>[n_nodes, n_nodes]</code>;</li>
<li><code>e</code>: edge attributes of shape <code>[n_edges, n_edge_features]</code>;</li>
<li><code>i</code>: batch index of shape <code>[n_nodes]</code>.</li>
</ul>
<p><code>labels</code> have shape <code>[batch, n_labels]</code> if <code>node_level=False</code> or
<code>[n_nodes, n_labels]</code> otherwise.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/data/loaders.py#L340">[source]</a></span></p>
<h4 id="batchloader">BatchLoader</h4>
<pre><code class="language-python">spektral.data.loaders.BatchLoader(dataset, mask=False, batch_size=1, epochs=None, shuffle=True)
</code></pre>
<p>A Loader for <a href="https://graphneural.network/data-modes/#batch-mode">batch mode</a>.</p>
<p>This loader returns batches of graphs stacked along an extra dimension,
with all "node" dimensions padded to be equal among all graphs.</p>
<p>If <code>n_max</code> is the number of nodes of the biggest graph in the batch, then
the padding consist of adding zeros to the node features, adjacency matrix,
and edge attributes of each graph so that they have shapes
<code>(n_max, n_node_features)</code>, <code>(n_max, n_max)</code>, and
<code>(n_max, n_max, n_edge_features)</code> respectively.</p>
<p>The zero-padding is done batch-wise, which saves up memory at the cost of
more computation. If latency is an issue but memory isn't, or if the
dataset has graphs with a similar number of nodes, you can use
the <code>PackedBatchLoader</code> that first zero-pads all the dataset and then
iterates over it.</p>
<p>Note that the adjacency matrix and edge attributes are returned as dense
arrays (mostly due to the lack of support for sparse tensor operations for
rank &gt;2).</p>
<p>Only graph-level labels are supported with this loader (i.e., labels are not
zero-padded because they are assumed to have no "node" dimensions).</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>dataset</code>: a graph Dataset;</li>
<li><code>mask</code>: if True, node attributes will be extended with a binary mask that
indicates valid nodes (the last feature of each node will be 1 if the node is valid
and 0 otherwise). Use this flag in conjunction with layers.base.GraphMasking to
start the propagation of masks in a model.</li>
<li><code>batch_size</code>: size of the mini-batches;</li>
<li><code>epochs</code>: number of epochs to iterate over the dataset. By default (<code>None</code>)
iterates indefinitely;</li>
<li><code>shuffle</code>: whether to shuffle the data at the start of each epoch.</li>
</ul>
<p><strong>Output</strong></p>
<p>For each batch, returns a tuple <code>(inputs, labels)</code>.</p>
<p><code>inputs</code> is a tuple containing:</p>
<ul>
<li><code>x</code>: node attributes of shape <code>[batch, n_max, n_node_features]</code>;</li>
<li><code>a</code>: adjacency matrices of shape <code>[batch, n_max, n_max]</code>;</li>
<li><code>e</code>: edge attributes of shape <code>[batch, n_max, n_max, n_edge_features]</code>.</li>
</ul>
<p><code>labels</code> have shape <code>[batch, n_labels]</code>.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/data/loaders.py#L437">[source]</a></span></p>
<h4 id="packedbatchloader">PackedBatchLoader</h4>
<pre><code class="language-python">spektral.data.loaders.PackedBatchLoader(dataset, mask=False, batch_size=1, epochs=None, shuffle=True)
</code></pre>
<p>A <code>BatchLoader</code> that zero-pads the graphs before iterating over the dataset.
This means that <code>n_max</code> is computed over the whole dataset and not just
a single batch.</p>
<p>While using more memory than <code>BatchLoader</code>, this loader should reduce the
computational overhead of padding each batch independently.</p>
<p>Use this loader if:</p>
<ul>
<li>memory usage isn't an issue and you want to produce the batches as fast
as possible;</li>
<li>the graphs in the dataset have similar sizes and there are no outliers in
the dataset (i.e., anomalous graphs with many more nodes than the dataset
average).</li>
</ul>
<p><strong>Arguments</strong></p>
<ul>
<li><code>dataset</code>: a graph Dataset;</li>
<li><code>batch_size</code>: size of the mini-batches;</li>
<li><code>epochs</code>: number of epochs to iterate over the dataset. By default (<code>None</code>)
iterates indefinitely;</li>
<li><code>shuffle</code>: whether to shuffle the data at the start of each epoch.</li>
</ul>
<p><strong>Output</strong></p>
<p>For each batch, returns a tuple <code>(inputs, labels)</code>.</p>
<p><code>inputs</code> is a tuple containing:</p>
<ul>
<li><code>x</code>: node attributes of shape <code>[batch, n_max, n_node_features]</code>;</li>
<li><code>a</code>: adjacency matrices of shape <code>[batch, n_max, n_max]</code>;</li>
<li><code>e</code>: edge attributes of shape <code>[batch, n_max, n_max, n_edge_features]</code>.</li>
</ul>
<p><code>labels</code> have shape <code>[batch, ..., n_labels]</code>.</p>
<hr />
<p><span style="float:right;"><a href="https://github.com/danielegrattarola/spektral/blob/master/spektral/data/loaders.py#L533">[source]</a></span></p>
<h4 id="mixedloader">MixedLoader</h4>
<pre><code class="language-python">spektral.data.loaders.MixedLoader(dataset, batch_size=1, epochs=None, shuffle=True)
</code></pre>
<p>A Loader for <a href="https://graphneural.network/data-modes/#mixed-mode">mixed mode</a>.</p>
<p>This loader returns batches where the node and edge attributes are stacked
along an extra dimension, but the adjacency matrix is shared by all graphs.</p>
<p>The loader expects all node and edge features to have the same number of
nodes and edges.
The dataset is pre-packed like in a PackedBatchLoader.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>dataset</code>: a graph Dataset;</li>
<li><code>batch_size</code>: size of the mini-batches;</li>
<li><code>epochs</code>: number of epochs to iterate over the dataset. By default (<code>None</code>)
iterates indefinitely;</li>
<li><code>shuffle</code>: whether to shuffle the data at the start of each epoch.</li>
</ul>
<p><strong>Output</strong></p>
<p>For each batch, returns a tuple <code>(inputs, labels)</code>.</p>
<p><code>inputs</code> is a tuple containing:</p>
<ul>
<li><code>x</code>: node attributes of shape <code>[batch, n_nodes, n_node_features]</code>;</li>
<li><code>a</code>: adjacency matrix of shape <code>[n_nodes, n_nodes]</code>;</li>
<li><code>e</code>: edge attributes of shape <code>[batch, n_edges, n_edge_features]</code>.</li>
</ul>
<p><code>labels</code> have shape <code>[batch, ..., n_labels]</code>.</p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../transforms/" class="btn btn-neutral float-right" title="Transforms">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../datasets/" class="btn btn-neutral" title="Datasets"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
        <span>
          <a href="https://github.com/danielegrattarola/spektral/" class="fa fa-github" style="color: #fcfcfc"> GitHub</a>
        </span>
    
    
      <span><a href="../datasets/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../transforms/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../js/macros.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
